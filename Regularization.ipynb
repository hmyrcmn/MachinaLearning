{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5zKgCSY1+vOrhZ+H/b6as",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hmyrcmn/MachinaLearning/blob/main/Regularization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yüksek varyansın aşırı uydurmaya yol açtığı, yüksek önyargının ise yetersiz uydurmaya yol açtığı\n",
        "yetersiz uydurmayı çözmek için veri kümesinin boyutunu artırmanın ve modeli daha karmaşık hale getirmenin gerek\n",
        "\n",
        "L1, özellikleri kaldırmada etkilidir,\n",
        " L2 ise tüm katsayıları daraltır.\n",
        " Yetersiz uydurma: Model çok basit olduğunda eğitim verilerindeki kalıpları yakalayamaz.\n",
        "Aşırı uydurma: Model eğitim verilerine aşırı derecede uyduğunda, yeni verilere genelleme yapamaz.\n",
        "\n",
        "yüksek önyargının yetersizliğe yol açtığını ve yüksek varyansın aşırı uyuma yol açar.\n",
        "\n",
        "Yetersizliği çözmenin genel yaklaşımı, verileri daha karmaşık hale getirmektir. Eğitim setindeki gözlem sayısını artırabiliriz. Tahminleri etkileyebilecek yeni özellikler de ekleyebiliriz.\n",
        "\n",
        "\n",
        "Aşırı uydurma ve yüksek varyansın çözümü için genel fikir, verileri daha az karmaşık hale getirmektir. buda düzenlme ile mümkündür .\n",
        "Düzenlenme daha karmaşık kalıpların öğrenilmesini önler. Bunu, katsayıları sıfıra doğru daraltarak yapar, böylece daha az önemli özelliklerin etkisi azalır ve yüksek varyans önlenir. Düzenlileştirme, L1 ve L2 adı verilen kayıp işlevlerini kullanır.\n",
        "\n",
        "\n",
        "veri kümesinde aykırı değerler olduğunda, L2 kayıp işlevini kullanmak yararlı değildir, çünkü, gerçek ve tahmin edilen değerler arasındaki farkların karelerini almak çok daha büyük bir hataya yol açacaktı\n"
      ],
      "metadata": {
        "id": "F9HjvIyaRlz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import Ridge, LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n"
      ],
      "metadata": {
        "id": "QfZktyfDVBt_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"trainREG.csv\")\n"
      ],
      "metadata": {
        "id": "UclfN3k8VBrH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('SalePrice', axis=1)\n",
        "y = data.loc[:, 'SalePrice']\n"
      ],
      "metadata": {
        "id": "-o1cYZpjVBod"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "erinin %70'i eğitim için kullanılırken, %30'u test için kullanılır."
      ],
      "metadata": {
        "id": "8aXi_O28VozB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n"
      ],
      "metadata": {
        "id": "-KzWl9jeVBl3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_reg = LinearRegression()\n",
        "#ridge_reg = Ridge(alpha=0.05, normalize=True)\n",
        "ridge_reg = Ridge(alpha=0.05)\n"
      ],
      "metadata": {
        "id": "RH17GLVPVBjR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_reg.fit(X_train, y_train)\n",
        "ridge_reg.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "pE_tK7h4VBgL",
        "outputId": "cb60a9c7-2593-4455-f8f2-eb6254c474f4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ridge(alpha=0.05)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=0.05)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=0.05)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_pred = linear_reg.predict(X_test)\n",
        "ridge_pred = ridge_reg.predict(X_test)\n"
      ],
      "metadata": {
        "id": "Qgiloc-HVBcv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu hücrede, her iki modelin tahminlerinin gerçek değerlerle karşılaştırıldığı ortalama kare hata (MSE) hesaplanır ve sonuçlar ekrana yazdırılır. Bu, modellerin performansını karşılaştırmak için kullanılır. Ridge regresyonunun, düzenleme yaparak daha düşük bir MSE elde ettiği görülmektedir.\n",
        "\n",
        "Bu kodlar, bir veri seti üzerinde lineer ve ridge regresyonun nasıl uygulanacağını ve düzenlemenin nasıl etki ettiğini göstermektedir. Ridge regresyon, aşırı uydurmayı önlemeye yardımcı olabilir ve genellikle modelin daha iyi genelleme yapmasına yardımcı olabilir."
      ],
      "metadata": {
        "id": "9cF9RFgsWUoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear_mse = mean_squared_error(y_test, linear_pred)\n",
        "ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
        "\n",
        "print(f\"MSE without Ridge: {linear_mse}\")\n",
        "print(f\"MSE with Ridge : {ridge_mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DauIHNGrVBZI",
        "outputId": "37faa43f-1a0b-43d5-a92b-c2114f99e674"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE without Ridge: 1252817034.5581887\n",
            "MSE with Ridge : 1252677721.1999955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HS6BfHpSVBU7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNimPGLqRav7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MSE (Ortalama Kare Hata): MSE, bir regresyon modelinin tahminlerinin ne kadar iyi olduğunu ölçen bir metrik olarak kullanılır.\n",
        " Daha düşük MSE değerleri, modelin daha iyi tahminler yaptığını gösterir. Bu, regresyon modelinin gerçek verilere ne kadar yakın tahminlerde bulunduğunu gösterir.\n",
        "\n",
        "Kement Regresyonu (Lasso Regresyonu): Kement regresyonu, regresyon analizinde kullanılan bir yöntemdir. Bu yöntem, bir modelin katsayılarını sıfıra yaklaştırarak bazı özellikleri önemsiz hale getirir. Yani, bazı özelliklerin sonuç üzerindeki etkisini azaltır veya bu özellikleri modelde kullanmayı bırakır.\n",
        "\n",
        "λ (Lambda) Parametresi: Lambda, kement regresyonunda kullanılan bir ayar parametresidir. Bu parametre, ne kadar düzenleme veya \"cezalandırma\" yapılacağını kontrol eder. Daha büyük bir lambda değeri, daha fazla katsayının sıfıra yaklaşmasına neden olur ve böylece daha fazla özelliğin önemsiz hale gelmesine yol açar. Lambda'nın değeri, modelin ne kadar esnek veya katı olacağını belirler.\n",
        "\n",
        "Özelliklerin Önemi: Örneğin, saç rengi gibi bir özelliğin, IQ tahmini yaparken çok az veya hiç bir etkisi olmadığını düşünelim. Kement regresyonu, bu tür önemsiz özelliklerin katsayılarını sıfıra yaklaştırarak, modelin daha fazla bu özelliği kullanmamasını sağlar. Böylece, model daha az tahmin edici veya daha az karmaşık hale gelir.\n",
        "\n",
        "Sonuç olarak, kement regresyonu, regresyon modellerinin karmaşıklığını kontrol etmek ve gereksiz özellikleri elemek için kullanılan bir yöntemdir. Lambda parametresi, bu düzenlemeyi ne kadar yapacağımızı ayarlar, ve önemsiz özellikleri modelden çıkararak daha basit ve daha etkili modeller elde etmemizi sağlar."
      ],
      "metadata": {
        "id": "iiDRnmgcUH0h"
      }
    }
  ]
}